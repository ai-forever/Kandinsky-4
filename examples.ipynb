{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e666fa-07b4-46fd-a4b5-4b8b576b7296",
   "metadata": {},
   "source": [
    "# How to use: \n",
    "* Create ***device_map***. ***device_map*** is a dict or str indicating where each model of the pipeline is placed.\n",
    "* Create pipeline. You can do it by ***get_T2V_pipeline*** function which create pipeline with default settings. In this case ensure that you have ***weights*** folder with all models inside.\n",
    "  \n",
    "    Also you create pipeline with your own settings like config and pathes to all models.\n",
    "* You can change resolution in ***get_T2V_pipeline*** function using ***resolution*** parameter. (Only  512 available at this point, 512 is default)\n",
    "/*\n",
    "\n",
    "* Use created pipelines to generate video or image. Parameters are:\n",
    "    - ***text*** - prompt for video or image\n",
    "    - ***save_path*** - path where generated video will be saved, default \"./test.mp4\" (if you generate image then this parameter is not used)\n",
    "    - ***bs*** - number of generated video/images, but now only 1 is available\n",
    "    - ***time_length*** - length of video in seconds, default 12, pass 0 if you want to generate image\n",
    "    - ***width*** - width of generated video/image in pixels, default 512,\n",
    "    - ***height*** - height of generated video/image in pixels, default 512\n",
    "      \n",
    "        + only predefined pairs of width and height are available, for 512 resolution: (512, 512), (352, 736), (736, 352), (384, 672), (672, 384), (480, 544), (544, 480)\n",
    "      \n",
    "    - ***num_steps*** - number of steps in diffusion, default 4\n",
    "    - ***seed*** - random seed to fix generation, default None (random)\n",
    "\n",
    "All the examples of pipeline creation and usage are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4b5d30-3b93-4e75-88e4-ac6214f780e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython.display import Video\n",
    "from kandinsky import get_T2V_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477f6535-d1d2-4b59-be66-b2bdaa538bee",
   "metadata": {},
   "source": [
    "# 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f72c3c0-e0bf-4a75-a229-2d0b67328b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4357b97b24374f759d35b079532e7f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9965c3457744596afb3c40fdaf7e373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8378c33d85ce4807a4fedf915d20b0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e465811d864716a4199195d0849552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04be4be1034428fafbefa5921879401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'invert_scale_latents': False} were passed to AutoencoderKLCogVideoX, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    }
   ],
   "source": [
    "device_map = {\n",
    "    \"dit\": torch.device('cuda:0'), \n",
    "    \"vae\": torch.device('cuda:0'), \n",
    "    \"text_embedder\": torch.device('cuda:0')\n",
    "}\n",
    "\n",
    "pipe = get_T2V_pipeline(device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7bc1408-2a6a-4768-b8fd-f79e4325337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"The camera follows behind a white vintage SUV with a black roof rack as it speeds up a steep dirt road surrounded by pine trees on a steep mountain slope, dust kicks up from itâ€™s tires, the sunlight shines on the SUV as it speeds along the dirt road, casting a warm glow over the scene. The dirt road curves gently into the distance, with no other cars or vehicles in sight. The trees on either side of the road are redwoods, with patches of greenery scattered throughout. The car is seen from the rear following the curve with ease, making it seem as if it is on a rugged drive through the rugged terrain. The dirt road itself is surrounded by steep hills and mountains, with a clear blue sky above with wispy clouds.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "608d7217-b361-4013-9e5e-be783a2ed73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b898d62d87b24180a70930dee4b1000a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<video src=\"./test.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = pipe(\n",
    "    # seed=6655,\n",
    "    time_length=12,\n",
    "    width = 672,\n",
    "    height = 384,\n",
    "    save_path=\"./test.mp4\",\n",
    "    text=prompt,\n",
    ")\n",
    "\n",
    "Video(\"./test.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b624d96-6f98-4545-b9b9-0b220eb272b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-kovaleva_kandinsky4_cuda118]",
   "language": "python",
   "name": "conda-env-.mlspace-kovaleva_kandinsky4_cuda118-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
